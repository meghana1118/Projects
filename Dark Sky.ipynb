{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary Libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from pandas.io.json import json_normalize\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read excel file\n",
    "location=pd.read_csv(r'C:\\Users\\megha\\Documents\\Projects\\DarkSky\\store.csv') #105 store  IDs\n",
    "#API Key\n",
    "authorization_code='ffb7c6d0d32876c01496218fbd979218'\n",
    "#isolate latitude and longitude\n",
    "lat,long=location['LATITUDE'],location['LONGITUDE']\n",
    "store_id=location['LOC_ID'] # needed to append later in file\n",
    "#base url\n",
    "base_url=\"https://api.darksky.net/forecast/ffb7c6d0d32876c01496218fbd979218/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'currently'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c1a5e3af03cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'currently'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LATITUDE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'latitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LONGITUDE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'longitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'currently'"
     ]
    }
   ],
   "source": [
    "#Past date weather\n",
    "#Get time for history date\n",
    "from datetime import date, timedelta\n",
    "dates=[]\n",
    "start_date = date(2019, 12, 1)\n",
    "end_date = date(2019, 12, 5)\n",
    "delta = timedelta(days=1)\n",
    "while start_date <= end_date:\n",
    "    c=start_date.strftime(\"%d/%m/%Y\")\n",
    "    dates.append(c)\n",
    "    start_date += delta\n",
    "date_unix=[]\n",
    "for i in dates:\n",
    "    f=time.mktime(datetime.datetime.strptime(i, \"%d/%m/%Y\").timetuple())\n",
    "    date_unix.append(f)\n",
    "    \n",
    "#make list of URLs    \n",
    "url=''\n",
    "for i,j in zip(lat,long):\n",
    "    for k in date_unix:\n",
    "        url +=base_url+str(i)+str(',')+str(j)+str(',')+str(int(k))+str(\" \")\n",
    "    url_list=url.split(\" \")\n",
    "    url_list.remove('')\n",
    "    \n",
    "#Dataframe\n",
    "history=pd.DataFrame()\n",
    "for url in url_list:\n",
    "    response=requests.get(url)\n",
    "    r=response.json()\n",
    "    df=json_normalize(r['currently'])\n",
    "    df['LATITUDE']=r['latitude']\n",
    "    df['LONGITUDE']=r['longitude']\n",
    "    history= history.append(df, ignore_index=True)\n",
    "    history['date'] = pd.to_datetime(history['time'],unit='s')\n",
    "\n",
    "History_dates=pd.merge(location, history, on=['LATITUDE', 'LONGITUDE'])\n",
    "#History_dates.to_csv('History.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast for fututre\n",
    "#making a list of URLs\n",
    "url_f=''\n",
    "for i,j in zip(lat,long):\n",
    "    url_f +=base_url+str(i)+str(',')+str(j)+str(\" \")\n",
    "    url_list_f=url_f.split(\" \")\n",
    "    url_list_f.remove('')\n",
    "\n",
    "f=pd.DataFrame()\n",
    "for url,i in zip(url_list_f,store_id):\n",
    "    response=requests.get(url)\n",
    "    r=response.json()\n",
    "    data=json_normalize(r,['daily','data'],['latitude','longitude'])\n",
    "    data['date'] = pd.to_datetime(data['time'],unit='s')\n",
    "    data['store_id']=i\n",
    "    f = f.append(data, ignore_index=True)\n",
    "#Save as CSV   \n",
    "#f.to_csv('Forecasting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'total' is not defined\n"
     ]
    }
   ],
   "source": [
    "#https://docs.sqlalchemy.org/en/13/core/engines.html\n",
    "#https://pythontic.com/pandas/serialization/mysql\n",
    "#moving both dataframes to MySQL database\n",
    "table1='DarkSkyForecast'\n",
    "table2='DarkSkyHistory'\n",
    "sqlEngine = create_engine('mysql+pymysql://root:megh@n@1811@localhost/darksky', pool_recycle=3600)\n",
    "dbConnection = sqlEngine.connect() \n",
    "try:\n",
    "    frameh = History_dates.to_sql(table2, dbConnection, if_exists='fail');\n",
    "    framef = f.to_sql(table1, dbConnection, if_exists='fail')\n",
    "except ValueError as vx:\n",
    "    print(vx)\n",
    "except Exception as ex:   \n",
    "    print(ex)\n",
    "else:\n",
    "    print(\"Table %s created successfully.\"%tableName);   \n",
    "finally:\n",
    "    dbConnection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
